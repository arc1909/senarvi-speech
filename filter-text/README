These scripts read text segments, e.g. web pages, in the following format:

###### http://domain/page1
Text from page 1.
###### http://domain/page2
Text from page 2.

They can be used to score the text pages based on e.g. language model
perplexity, and filter out pages with score above or below a certain
threshold. They support splitting tasks for multiple parallel jobs.

For example, one might score text pages in input.pages using the
compute-perplexity.sh script, that reads text from standard input, and
writes the perplexity to standard output:

  score-pages.py --unit=each --scores=perplexity.scores compute-perplexity.sh input.pages

The text pages can be sorted, starting from the lowest perplexity,
based on the scores that were written in perplexity.scores. At the
same time, bigram language model perplexity on devel2.txt can be
computed periodically:

  sort-pages.py --devel-text=devel2.txt --order=2 --statistics=stats.csv perplexity.scores

Notice that devel2.txt should be different from the development text
used to score the text pages in the first place (if any). Finally,
stats.csv can be inspected to find the point of minimum perplexity,
and the score (say 65) can be used as the filtering threshold:

  filter-pages.py --max-score=65 --pages=input.pages --output=filtered.txt perplexity.scores

Author: Seppo Enarvi
http://users.marjaniemi.com/seppo/
